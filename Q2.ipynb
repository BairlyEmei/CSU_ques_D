{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Question 2\n",
    "导入必要的库"
   ],
   "id": "207ce86ac7c37ef9"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from random_forest_Q2 import *\n",
    "from scipy.optimize import minimize\n",
    "import itertools\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "import os\n",
    "from contextlib import redirect_stdout\n",
    "from datetime import datetime"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 预测人数\n",
    "### 随机森林模型主流程"
   ],
   "id": "8059af0ea2606451"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 1. 加载原始数据\n",
    "original_data = pd.read_excel('D题附件：法医物证多人身份鉴定问题数据集/附件2：不同混合比例的STR图谱数据_processed.xlsx')\n",
    "\n",
    "# 2. 加载并预处理模型数据\n",
    "df = load_and_preprocess(data_path=\"data/enhanced_processed_Q2_data.xlsx\")\n",
    "X = df.drop(['people', 'gene_from', 'proportion'], axis=1)\n",
    "y = df['people']\n",
    "\n",
    "# 划分训练集/测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "test_sample_files = X_test['sample_file']\n",
    "\n",
    "# 3. 模型训练\n",
    "rf_model, feature_selector = train_random_forest(\n",
    "    X_train.drop('sample_file', axis=1),\n",
    "    y_train\n",
    ")\n",
    "\n",
    "# 4. 模型预测\n",
    "X_test_selected = feature_selector.transform(X_test.drop('sample_file', axis=1))\n",
    "y_pred = rf_model.predict(X_test_selected)\n",
    "y_proba = rf_model.predict_proba(X_test_selected)\n",
    "\n",
    "# 5. 模型评估\n",
    "print(\"=\" * 40)\n",
    "print(\"模型评估指标：\")\n",
    "print(f\"准确率: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(f\"精确率: {precision_score(y_test, y_pred, average='macro'):.4f}\")\n",
    "print(f\"召回率: {recall_score(y_test, y_pred, average='macro'):.4f}\")\n",
    "print(f\"F1分数: {f1_score(y_test, y_pred, average='macro'):.4f}\")\n",
    "print(f\"AUC值: {roc_auc_score(y_test, y_proba, multi_class='ovo'):.4f}\")\n",
    "\n",
    "# 6. 可视化输出\n",
    "# 特征重要性图\n",
    "plot_feature_importance(rf_model, X.columns.tolist(), \"images/Q2/feature_importance.png\")\n",
    "\n",
    "# ROC曲线\n",
    "plot_roc_curve(y_test, y_proba, \"images/Q2/roc_curve.png\")\n",
    "\n",
    "# 混淆矩阵\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm,\n",
    "                              display_labels=rf_model.classes_)\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"混淆矩阵\")\n",
    "plt.savefig(\"images/Q2/confusion_matrix.png\", dpi=300)\n",
    "plt.show()\n",
    "plt.close()"
   ],
   "id": "c6a869a71745929d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 提取测试集数据结果",
   "id": "77e53d81091757cf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#合并到原始数据\n",
    "predictions = pd.DataFrame({\n",
    "    'Sample File': test_sample_files,\n",
    "    'predicted_people': y_pred\n",
    "})\n",
    "data_test = original_data[original_data['Sample File'].isin(test_sample_files)]\n",
    "data_test = data_test.merge(predictions, on='Sample File', how='left')\n",
    "\n",
    "# 将predicted_people列移动到第5列位置\n",
    "cols = data_test.columns.tolist()\n",
    "cols.remove('predicted_people')\n",
    "cols.insert(4, 'predicted_people')  # 插入到第5列位置(索引4)\n",
    "data_test = data_test[cols]\n",
    "\n",
    "# 验证每个样本的预测值唯一性\n",
    "assert data_test.groupby('Sample File')['predicted_people'].nunique().max() == 1\n",
    "\n",
    "# 创建结果目录\n",
    "if not os.path.exists('result'):\n",
    "    os.makedirs('result')\n",
    "\n",
    "# 输出结果\n",
    "data_test.to_excel('result/Q2_data_test.xlsx', index=False)"
   ],
   "id": "462494762150e248",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## 预测比例\n",
    "### 生成贡献矩阵A_i，归一化样本矩阵C"
   ],
   "id": "565631ca5536014b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 基因座数据配置\n",
    "GENE_LOCI = {\n",
    "    'D8S1179': [10, 11, 12, 13, 14, 15, 16],\n",
    "    'D21S11': [24.3, 27, 28, 29, 30, 31, 31.2, 32, 32.2, 33, 33.2, 35, 36],\n",
    "    'D7S820': [7, 8, 9, 10, 11, 12, 13],\n",
    "    'CSF1PO': [7, 8, 9, 10, 11, 12, 13],\n",
    "    'D3S1358': [14, 15, 16, 17, 18],\n",
    "    'TH01': [5, 6, 7, 8, 9, 9.3],\n",
    "    'D13S317': [8, 9, 10, 11, 12, 13, 14],\n",
    "    'D16S539': [8, 9, 10, 11, 12, 13, 14],\n",
    "    'D2S1338': [16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26],\n",
    "    'D19S433': [10, 10.2, 11, 12, 12.2, 13, 13.2, 14, 14.2, 15, 15.2, 16, 16.2],\n",
    "    'vWA': [11, 12, 13, 14, 15, 16, 17, 18, 19, 20],\n",
    "    'TPOX': [6, 7, 8, 9, 10, 11, 12],\n",
    "    'D18S51': [10, 12, 13, 14, 15, 16, 17, 18, 19, 20, 22, 23],\n",
    "    'AMEL': ['X', 'Y'],\n",
    "    'D5S818': [7, 8, 9, 10, 11, 12, 13, 14],\n",
    "    'FGA': [19, 20, 21, 21.2, 22, 22.2, 23, 24, 25, 26, 27, 28]\n",
    "}"
   ],
   "id": "3657328a3d4e7cc4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 生成C矩阵\n",
    "def generate_C_matrix(sample_name, data_test, GENE_LOCI):\n",
    "    \"\"\"\n",
    "    根据C_vector的非零位置生成该基因座的合法等位基因组合（去重）并应用动态噪声过滤\n",
    "\n",
    "    参数:\n",
    "    C_vector: 当前基因座的峰高向量\n",
    "    alleles: 当前基因座的等位基因列表\n",
    "\n",
    "    返回:\n",
    "    该基因座所有合法组合的列表（去重）\n",
    "    \"\"\"\n",
    "\n",
    "    # 初始化结果容器\n",
    "    matrix_data = []          # 归一化的峰高比例向量\n",
    "    locus_raw_heights = []    # 原始峰高列表（每个等位基因的原始峰高）\n",
    "    locus_total_heights = []  # 每个基因座的原始总峰高（过滤噪声后）\n",
    "\n",
    "    # 获取基因座顺序列表\n",
    "    loci_order = list(GENE_LOCI.keys())\n",
    "\n",
    "    # 处理每个基因座\n",
    "    for locus_name in loci_order:\n",
    "        alleles = GENE_LOCI[locus_name]\n",
    "        # 转换标准等位基因格式\n",
    "        if locus_name == 'AMEL':\n",
    "            std_alleles = [str(a).upper() for a in alleles]\n",
    "        else:\n",
    "            std_alleles = [f\"{float(a):g}\" for a in alleles]\n",
    "\n",
    "        # 获取当前基因座数据\n",
    "        sample_mask = (\n",
    "            (data_test['Sample File'] == sample_name) &\n",
    "            (data_test['Marker'].str.upper() == locus_name.upper())\n",
    "        )\n",
    "        locus_data = data_test[sample_mask].copy()\n",
    "\n",
    "        # 初始化峰高向量\n",
    "        locus_vector = [0.0] * len(std_alleles)\n",
    "        raw_heights = [0.0] * len(std_alleles)  # 存储原始峰高\n",
    "        total_height = 0.0\n",
    "\n",
    "        if not locus_data.empty:\n",
    "            # 第一遍：收集所有峰高数据\n",
    "            allele_counts = defaultdict(float)\n",
    "\n",
    "            # 遍历所有Allele列\n",
    "            for col in [c for c in locus_data.columns if c.startswith('Allele')]:\n",
    "                col_num = col.split()[-1]\n",
    "                height_col = f'Height {col_num}'\n",
    "\n",
    "                # 提取等位基因和峰高\n",
    "                allele = str(locus_data[col].iloc[0]).strip()\n",
    "                height = locus_data[height_col].iloc[0]\n",
    "\n",
    "                # 过滤无效数据\n",
    "                if pd.isna(allele) or pd.isna(height) or 'OL' in allele or 'off-ladder' in allele.lower():\n",
    "                    continue\n",
    "\n",
    "                # 格式处理\n",
    "                try:\n",
    "                    processed_allele = (\n",
    "                        allele.upper() if locus_name == 'AMEL'\n",
    "                        else f\"{float(allele):g}\"\n",
    "                    )\n",
    "                except ValueError:\n",
    "                    continue\n",
    "\n",
    "                # 累加峰高值\n",
    "                if processed_allele in std_alleles:\n",
    "                    allele_index = std_alleles.index(processed_allele)\n",
    "                    raw_heights[allele_index] += float(height)\n",
    "                    total_height += float(height)\n",
    "                    allele_counts[processed_allele] += float(height)\n",
    "\n",
    "            # 动态噪声过滤\n",
    "            if total_height > 0 and any(h > 0 for h in raw_heights):\n",
    "                # 获取有效峰高值（非零）\n",
    "                valid_heights = [h for h in raw_heights if h > 0]\n",
    "\n",
    "                if valid_heights:\n",
    "                    # 计算最大峰高和总峰高\n",
    "                    max_peak = max(valid_heights)\n",
    "                    total_valid = sum(valid_heights)\n",
    "\n",
    "                    # 设置动态阈值\n",
    "                    threshold = max(0.1 * max_peak, 0.01 * total_valid)\n",
    "\n",
    "                    # 应用阈值过滤\n",
    "                    for i in range(len(raw_heights)):\n",
    "                        if raw_heights[i] < threshold:\n",
    "                            # 将低于阈值的峰高设为0\n",
    "                            total_height -= raw_heights[i]\n",
    "                            raw_heights[i] = 0.0\n",
    "                else:\n",
    "                    # 如果没有有效峰高，重置总峰高\n",
    "                    total_height = 0.0\n",
    "            else:\n",
    "                # 如果没有峰高数据，保持为0\n",
    "                total_height = 0.0\n",
    "\n",
    "        # 计算归一化比例（仅当总峰高大于0）\n",
    "        if total_height > 0:\n",
    "            # 填充归一化峰高比例\n",
    "            for i in range(len(std_alleles)):\n",
    "                locus_vector[i] = raw_heights[i] / total_height\n",
    "        else:\n",
    "            # 如果没有峰高数据，保持为0\n",
    "            locus_vector = [0.0] * len(std_alleles)\n",
    "\n",
    "        matrix_data.append(locus_vector)\n",
    "        locus_raw_heights.append(raw_heights)       # 保存过滤后的原始峰高列表\n",
    "        locus_total_heights.append(total_height)    # 保存过滤后的原始总峰高\n",
    "\n",
    "    return matrix_data, locus_total_heights, locus_raw_heights"
   ],
   "id": "dfc243c26d0ca652",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 生成A矩阵\n",
    "def generate_valid_allele_combinations_for_locus(C_vector, alleles):\n",
    "    \"\"\"\n",
    "    根据C_vector的非零位置生成该基因座的合法等位基因组合（去重）\n",
    "\n",
    "    参数:\n",
    "    C_vector: 当前基因座的峰高向量\n",
    "    alleles: 当前基因座的等位基因列表\n",
    "\n",
    "    返回:\n",
    "    该基因座所有合法组合的列表（去重）\n",
    "    \"\"\"\n",
    "\n",
    "    n = len(alleles)\n",
    "    if n == 0:\n",
    "        return []\n",
    "\n",
    "    # 1. 找出C_vector中非零位置的索引\n",
    "    non_zero_indices = [i for i, height in enumerate(C_vector) if height > 0]\n",
    "\n",
    "    # 2. 特殊处理性染色体基因座（AMEL）\n",
    "    # 检测是否为AMEL基因座：检查是否包含X或Y等位基因\n",
    "    is_amel = False\n",
    "    for allele in alleles:\n",
    "        if isinstance(allele, str) and any(char in allele.upper() for char in ['X', 'Y']):\n",
    "            is_amel = True\n",
    "            break\n",
    "\n",
    "    if is_amel:\n",
    "        # 对于性染色体基因座，只允许特定组合\n",
    "        valid_combinations = []\n",
    "\n",
    "        # 找出X和Y的位置\n",
    "        x_index = None\n",
    "        y_index = None\n",
    "\n",
    "        for i, allele in enumerate(alleles):\n",
    "            if isinstance(allele, str):\n",
    "                allele_upper = allele.upper()\n",
    "                if 'X' in allele_upper:\n",
    "                    x_index = i\n",
    "                if 'Y' in allele_upper:\n",
    "                    y_index = i\n",
    "\n",
    "        # 女性组合：XX（纯合子）\n",
    "        if x_index is not None:\n",
    "            female_vec = [0] * n\n",
    "            female_vec[x_index] = 2\n",
    "            valid_combinations.append(female_vec)\n",
    "\n",
    "        # 男性组合：XY（杂合子）\n",
    "        if x_index is not None and y_index is not None and x_index != y_index:\n",
    "            male_vec = [0] * n\n",
    "            male_vec[x_index] = 1\n",
    "            male_vec[y_index] = 1\n",
    "            valid_combinations.append(male_vec)\n",
    "\n",
    "        return valid_combinations\n",
    "\n",
    "    # 3. 对于普通基因座，使用标准生成方法\n",
    "    # 如果没有非零位置，返回空列表\n",
    "    if not non_zero_indices:\n",
    "        return []\n",
    "\n",
    "    valid_combinations = []\n",
    "\n",
    "    # 生成纯合子组合（只考虑非零位置）\n",
    "    for i in non_zero_indices:\n",
    "        vec = [0] * n\n",
    "        vec[i] = 2\n",
    "        valid_combinations.append(vec)\n",
    "\n",
    "    # 生成杂合子组合（只考虑非零位置）\n",
    "    for i in range(len(non_zero_indices)):\n",
    "        for j in range(i+1, len(non_zero_indices)):\n",
    "            idx_i = non_zero_indices[i]\n",
    "            idx_j = non_zero_indices[j]\n",
    "            vec = [0] * n\n",
    "            vec[idx_i] = 1\n",
    "            vec[idx_j] = 1\n",
    "            valid_combinations.append(vec)\n",
    "\n",
    "    return valid_combinations\n",
    "\n",
    "\n",
    "def get_sorted_combinations(valid_combs, k):\n",
    "    \"\"\"\n",
    "    生成去重后的k个贡献者组合（考虑组合相同但顺序不同的情况）\n",
    "\n",
    "    参数:\n",
    "    valid_combs: 合法基因型组合列表\n",
    "    k: 贡献者数量\n",
    "\n",
    "    返回:\n",
    "    去重后的组合列表\n",
    "    \"\"\"\n",
    "    if not valid_combs:\n",
    "        return []\n",
    "\n",
    "    # 使用集合去除重复组合\n",
    "    unique_combs = set()\n",
    "\n",
    "    try:\n",
    "        # 生成所有可能的组合\n",
    "        for comb_group in product(valid_combs, repeat=k):\n",
    "            # 对组内的基因型进行排序（不考虑顺序）\n",
    "            sorted_group = tuple(sorted(tuple(comb) for comb in comb_group))\n",
    "            unique_combs.add(sorted_group)\n",
    "\n",
    "        # 转换回原始形式\n",
    "        result = []\n",
    "        for comb_tuple in unique_combs:\n",
    "            group = []\n",
    "            for genotype in comb_tuple:\n",
    "                # 查找原始组合（可能需要检查是否匹配）\n",
    "                group.append(list(genotype))\n",
    "            if group:\n",
    "                result.append(group)\n",
    "\n",
    "        return result\n",
    "    except Exception as e:\n",
    "        print(f\"  生成去重组合时出错: {str(e)}\")\n",
    "        return []"
   ],
   "id": "6514ef807e293dc5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 范数最优化求解",
   "id": "9e5100f4e3d88d2d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def estimate_contributors_by_locus(k, C_matrix, locus_total_heights, locus_raw_heights, GENE_LOCI):\n",
    "    \"\"\"\n",
    "    按基因座优化并加权平均的贡献者比例估计（使用首个基因座作为全局参考）\n",
    "    \"\"\"\n",
    "\n",
    "    loci_order = list(GENE_LOCI.keys())\n",
    "    n_loci = len(loci_order)\n",
    "\n",
    "    # 存储每个基因座的结果\n",
    "    locus_results = []\n",
    "    best_combinations = []\n",
    "    reference_p = None  # 全局参考比例向量\n",
    "\n",
    "    # 1. 计算权重 - 使用原始总峰高\n",
    "    weights = []\n",
    "    for i, locus_name in enumerate(loci_order):\n",
    "        # 使用原始总峰高计算权重\n",
    "        total_allele_height = locus_total_heights[i]\n",
    "        weight_i = np.sqrt(total_allele_height) if total_allele_height > 0 else 0\n",
    "        weights.append(weight_i)\n",
    "\n",
    "    # 归一化权重\n",
    "    total_omega = sum(weights)\n",
    "    if total_omega > 0:\n",
    "        normalized_weights = [w / total_omega for w in weights]\n",
    "    else:\n",
    "        normalized_weights = [1/n_loci] * n_loci\n",
    "\n",
    "    # 2. 初始化全局参考（第一个基因座）\n",
    "    print(f\"开始按基因座优化，贡献者人数k={k}\")\n",
    "    print(f\"将使用第一个基因座作为全局参考基准\")\n",
    "\n",
    "    for i, locus_name in enumerate(loci_order):\n",
    "        C_vector = np.array(C_matrix[i])  # 归一化峰高比例\n",
    "        raw_heights = locus_raw_heights[i]  # 原始峰高列表\n",
    "        total_height = locus_total_heights[i]  # 原始总峰高\n",
    "        alleles = GENE_LOCI[locus_name]\n",
    "\n",
    "        # 动态生成合法组合（基于原始峰高）\n",
    "        valid_combs = generate_valid_allele_combinations_for_locus(C_vector, alleles)\n",
    "\n",
    "        # 打印详细峰高信息\n",
    "        non_zero_alleles = []\n",
    "        for j, h in enumerate(raw_heights):\n",
    "            if h > 0:\n",
    "                non_zero_alleles.append(f\"{alleles[j]}: {h:.1f}\")\n",
    "\n",
    "        print(f\"\\n处理基因座 '{locus_name}'，原始总峰高={total_height:.1f}\")\n",
    "\n",
    "        min_residual = float('inf')\n",
    "        best_p = None\n",
    "        best_combo = None\n",
    "\n",
    "        # 检查无效数据情况 - 提供默认值\n",
    "        if not valid_combs or total_height <= 0:\n",
    "            uniform_p = np.ones(k) / k\n",
    "            locus_results.append(uniform_p)\n",
    "            best_combinations.append([np.zeros(len(alleles))] * k)\n",
    "            print(f\"  无有效数据，使用均匀分布: {uniform_p.round(3)}\")\n",
    "            continue\n",
    "\n",
    "        # 生成去重后的组合\n",
    "        comb_product = get_sorted_combinations(valid_combs, k)\n",
    "        total_combs = len(comb_product) if comb_product is not None else 0\n",
    "        print(f\"  考虑{total_combs}种组合（去重后）...\", end='', flush=True)\n",
    "\n",
    "        # 如果组合数量为0，跳过优化\n",
    "        if total_combs == 0:\n",
    "            uniform_p = np.ones(k) / k\n",
    "            best_combo = [valid_combs[0]] * k if valid_combs else [np.zeros(len(alleles))] * k\n",
    "            best_p = uniform_p\n",
    "            min_residual = 0.0\n",
    "        else:\n",
    "            for comb in comb_product:\n",
    "                A_matrix = np.array(comb).T\n",
    "\n",
    "                def objective(p):\n",
    "                    return np.linalg.norm(A_matrix @ p - C_vector)\n",
    "\n",
    "                constraints = (\n",
    "                    {'type': 'eq', 'fun': lambda p: np.sum(p) - 1},\n",
    "                    {'type': 'ineq', 'fun': lambda p: p}\n",
    "                )\n",
    "\n",
    "                p0 = np.ones(k) / k\n",
    "                try:\n",
    "                    res = minimize(objective, p0, method='SLSQP', constraints=constraints)\n",
    "\n",
    "                    if res.success and res.fun < min_residual:\n",
    "                        min_residual = res.fun\n",
    "                        best_p = res.x\n",
    "                        best_combo = comb\n",
    "                except Exception as e:\n",
    "                    # 优化可能失败，但继续尝试其他组合\n",
    "                    continue\n",
    "\n",
    "        # 如果没有找到有效组合，使用均匀分布\n",
    "        if best_p is None:\n",
    "            print(f\"\\n  警告: 未找到有效组合，使用均匀分布\")\n",
    "            best_p = np.ones(k) / k\n",
    "            best_combo = [valid_combs[0]] * k if valid_combs else [np.zeros(len(alleles))] * k\n",
    "\n",
    "        # 归一化比例 - 添加空值检查\n",
    "        best_p = np.clip(best_p, 0, None) if best_p is not None else np.ones(k) / k\n",
    "        best_p_sum = np.sum(best_p)\n",
    "        if best_p_sum > 0:\n",
    "            best_p /= best_p_sum\n",
    "\n",
    "        # 如果是第一个基因座，设为全局参考\n",
    "        if i == 0:\n",
    "            reference_p = best_p.copy()\n",
    "            print(f\"完成! 最小残差={min_residual:.4f}\")\n",
    "            print(f\"  设为全局参考比例: {np.round(best_p, 4)}\")\n",
    "        else:\n",
    "            # 与参考比例调整顺序 - 添加空值检查\n",
    "            if best_combo and all(combo is not None for combo in best_combo):\n",
    "                best_p, best_combo = match_to_reference(reference_p, best_p, best_combo)\n",
    "            print(f\"完成! 最小残差={min_residual:.4f}\")\n",
    "            print(f\"  调整后比例: {np.round(best_p, 4)}\")\n",
    "\n",
    "        # 输出基因型组合 - 添加空值检查\n",
    "        print(f\"  贡献者基因型组合:\")\n",
    "        if best_combo:\n",
    "            for p_idx in range(k):\n",
    "                if p_idx < len(best_combo):  # 防止索引越界\n",
    "                    combo_vec = best_combo[p_idx]\n",
    "                    allele_strs = []\n",
    "                    for idx, count in enumerate(combo_vec):\n",
    "                        if count > 0:\n",
    "                            # 获取原始峰高值（如果可用）\n",
    "                            raw_height = \"\"\n",
    "                            if len(raw_heights) > idx and raw_heights[idx] > 0:\n",
    "                                raw_height = f\"({raw_heights[idx]:.1f})\"\n",
    "\n",
    "                            allele_val = alleles[idx]\n",
    "                            if isinstance(allele_val, float) and allele_val.is_integer():\n",
    "                                allele_strs.append(f\"{int(allele_val)}×{int(count)}\")\n",
    "                            else:\n",
    "                                allele_strs.append(f\"{allele_val}×{int(count)}\")\n",
    "                    print(f\"    贡献者{p_idx+1}: {' + '.join(allele_strs)}\")\n",
    "                else:\n",
    "                    print(f\"    贡献者{p_idx+1}: 无数据\")\n",
    "        else:\n",
    "            print(\"    无基因型组合数据\")\n",
    "\n",
    "        # 保存结果\n",
    "        locus_results.append(best_p)\n",
    "        best_combinations.append(best_combo)\n",
    "\n",
    "    # 3. 加权平均\n",
    "    final_p = np.zeros(k)\n",
    "    for j in range(k):\n",
    "        for i in range(n_loci):\n",
    "            if i < len(locus_results) and locus_results[i] is not None and j < len(locus_results[i]):\n",
    "                final_p[j] += normalized_weights[i] * locus_results[i][j]\n",
    "\n",
    "    final_p_sum = np.sum(final_p)\n",
    "    if final_p_sum > 0:\n",
    "        final_p /= final_p_sum\n",
    "\n",
    "    # 输出最终结果\n",
    "    print(\"\\n所有基因座处理完成，开始加权平均\")\n",
    "    print(f\"最终混合比例: {np.round(final_p, 4)}\")\n",
    "    print(f\"比例总和: {np.sum(final_p):.4f}\")\n",
    "\n",
    "    return final_p, locus_results, normalized_weights\n",
    "\n",
    "def match_to_reference(reference_p, best_p, best_combo):\n",
    "    k = len(reference_p)\n",
    "    if k == 1 or reference_p is None or best_p is None:\n",
    "        return best_p, best_combo\n",
    "\n",
    "    try:\n",
    "        # 计算原始顺序相关性\n",
    "        corr_original = np.corrcoef(reference_p, best_p)[0, 1]\n",
    "\n",
    "        # 当k=2时尝试交换顺序\n",
    "        if k == 2:\n",
    "            swapped_p = best_p[::-1].copy()\n",
    "            swapped_combo = best_combo[::-1]\n",
    "            corr_swapped = np.corrcoef(reference_p, swapped_p)[0, 1]\n",
    "\n",
    "            if corr_swapped > corr_original:\n",
    "                # print(f\"  调整顺序以匹配参考（原始相关性={corr_original:.3f}, 调整后={corr_swapped:.3f})\")\n",
    "                return swapped_p, swapped_combo\n",
    "\n",
    "        # 当k>2时尝试所有排列\n",
    "        else:\n",
    "            best_perm = list(range(k))\n",
    "            best_corr = corr_original\n",
    "\n",
    "            # 尝试所有可能的排列\n",
    "            for perm in itertools.permutations(range(k)):\n",
    "                perm = list(perm)\n",
    "                permuted_p = [best_p[i] for i in perm]\n",
    "                permuted_combo = [best_combo[i] for i in perm]\n",
    "                corr = np.corrcoef(reference_p, permuted_p)[0, 1]\n",
    "\n",
    "                if corr > best_corr:\n",
    "                    best_corr = corr\n",
    "                    best_perm = perm\n",
    "                    # print(f\"  发现更好顺序: 相关性={corr:.3f}\")\n",
    "\n",
    "            # 应用最佳排列\n",
    "            if best_perm != list(range(k)):\n",
    "                permuted_p = [best_p[i] for i in best_perm]\n",
    "                permuted_combo = [best_combo[i] for i in best_perm]\n",
    "                # print(f\"  应用最佳排列: {best_perm}, 相关性={best_corr:.3f}\")\n",
    "                return permuted_p, permuted_combo\n",
    "\n",
    "        return best_p, best_combo\n",
    "    except Exception as e:\n",
    "        print(f\"  匹配顺序时出错: {str(e)}\")\n",
    "        return best_p, best_combo\n"
   ],
   "id": "8904d4c5da3c55aa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 主流程",
   "id": "8ca516b2f69b4d20"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 创建汇总结果DataFrame\n",
    "summary_data = []\n",
    "sample_names = data_test['Sample File'].unique()\n",
    "\n",
    "# 遍历每个样本\n",
    "for i in range(0, len(sample_names)):\n",
    "    sample_name = sample_names[i]\n",
    "    print(f\"\\n开始处理样本: {sample_name}\")\n",
    "\n",
    "    # 创建日志文件路径\n",
    "    log_filename = f\"result/{sample_name.replace('/', '_').replace(':', '_')}.log\"\n",
    "\n",
    "    # 打开日志文件用于记录输出\n",
    "    with open(log_filename, 'w') as log_file:\n",
    "        with redirect_stdout(log_file):\n",
    "            print(f\"处理样本: {sample_name}\")\n",
    "            print(f\"开始时间: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "            print(\"=\"*80)\n",
    "\n",
    "            try:\n",
    "                # 1. 生成C矩阵、总峰高和原始峰高\n",
    "                print(f\"步骤1: 生成基因座峰高矩阵\")\n",
    "                C_matrix, locus_total_heights, locus_raw_heights = generate_C_matrix(sample_name, data_test, GENE_LOCI)\n",
    "\n",
    "                # 2. 获取贡献者人数\n",
    "                print(f\"步骤2: 获取预测贡献者数量\")\n",
    "                k = data_test[data_test['Sample File'] == sample_name]['predicted_people'].iloc[0]\n",
    "                print(f\"  预测贡献者人数: {k}\")\n",
    "\n",
    "                # 3. 执行优化\n",
    "                print(f\"步骤3: 开始优化计算\")\n",
    "                final_p, locus_results, weights = estimate_contributors_by_locus(\n",
    "                    k, C_matrix, locus_total_heights, locus_raw_heights, GENE_LOCI\n",
    "                )\n",
    "\n",
    "                # 4. 记录结果\n",
    "                print(f\"步骤4: 记录优化结果\")\n",
    "                print(f\"最终估计比例: {np.round(final_p, 4)}\")\n",
    "                print(f\"比例总和: {np.sum(final_p):.4f}\")\n",
    "                print(f\"权重分布: {np.round(weights, 4)}\")\n",
    "\n",
    "                # 添加到汇总数据\n",
    "                summary_row = {\n",
    "                    'Sample': sample_name,\n",
    "                    'Contributors': k,\n",
    "                    'Processing_Time': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "                }\n",
    "\n",
    "                # 添加每个贡献者的比例\n",
    "                for i in range(k):\n",
    "                    summary_row[f'Contributor_{i+1}_P'] = final_p[i]\n",
    "\n",
    "                # 添加权重信息\n",
    "                for i, locus_name in enumerate(GENE_LOCI.keys()):\n",
    "                    weight = weights[i] if i < len(weights) else 0\n",
    "                    summary_row[f'Weight_{locus_name}'] = weight\n",
    "\n",
    "                summary_data.append(summary_row)\n",
    "\n",
    "                # 5. 保存基因座结果到CSV\n",
    "                locus_results_df = pd.DataFrame({\n",
    "                    'Locus': list(GENE_LOCI.keys()),\n",
    "                    'Total_Raw_Height': locus_total_heights,\n",
    "                    'Final_Weight': weights\n",
    "                })\n",
    "\n",
    "                # 添加每个贡献者的比例\n",
    "                for i in range(k):\n",
    "                    locus_results_df[f'Contributor_{i+1}_P'] = [p[i] if i < len(p) else 0 for p in locus_results]\n",
    "\n",
    "                locus_results_df.to_csv(f\"result/{sample_name.replace('/', '_').replace(':', '_')}_locus_results.csv\", index=False)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"处理样本 {sample_name} 时出错: {str(e)}\")\n",
    "                # 添加到汇总数据（错误标记）\n",
    "                summary_data.append({\n",
    "                    'Sample': sample_name,\n",
    "                    'Contributors': 'ERROR',\n",
    "                    'Processing_Time': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "                    'Error': str(e)\n",
    "                })\n",
    "\n",
    "            print(\"=\"*80)\n",
    "            print(f\"结束时间: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "            print(f\"结果已保存到: {log_filename}\")\n",
    "\n",
    "    print(f\"完成样本 {sample_name} 的处理\")\n",
    "\n",
    "# 创建汇总DataFrame\n",
    "if summary_data:\n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "    # 重新排列列（样本信息在前）\n",
    "    col_order = ['Sample', 'Contributors', 'Processing_Time', 'Error']\n",
    "    for i in range(1, 6):  # 最多支持5个贡献者\n",
    "        col_name = f'Contributor_{i}_P'\n",
    "        if col_name in summary_df.columns:\n",
    "            col_order.append(col_name)\n",
    "\n",
    "    # 添加权重列\n",
    "    locus_order = list(GENE_LOCI.keys())\n",
    "    for locus_name in locus_order:\n",
    "        col_name = f'Weight_{locus_name}'\n",
    "        if col_name in summary_df.columns:\n",
    "            col_order.append(col_name)\n",
    "\n",
    "    # 修改列选择逻辑，确保只选择存在的列\n",
    "    col_order = [col_name for col_name in col_order if col_name in summary_df.columns]\n",
    "\n",
    "    # 然后进行列选择\n",
    "    summary_df = summary_df[col_order]\n",
    "\n",
    "    # 保存汇总结果\n",
    "    summary_df.to_csv(\"result/summary_results.csv\", index=False)\n",
    "    print(f\"所有样本处理完成！汇总结果已保存到: result/summary_results.csv\")\n",
    "else:\n",
    "    print(\"未处理任何样本\")"
   ],
   "id": "5c0636992f318578",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
